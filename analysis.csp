package analysis

import analysis_impl as impl

function __impl_make_dataframe(header, data)
    var df = new dataframe
    df.header_map = new hash_map
    foreach idx in range(header.size) do df.header_map.insert(header.at(idx), idx)
    df.header = header
    df.data = data
    return move(df)
end

function __impl_make_dataframe_groupby(header, data, cols, groups)
    var df = new dataframe_groupby
    df.header_map = new hash_map
    foreach idx in range(header.size) do df.header_map.insert(header.at(idx), idx)
    df.header = header
    df.groups = groups
    df.g_cols = cols
    df.data = data
    return move(df)
end

struct operator
    var name = null
    var column = null
    var impl_func = null
    function as(str)
        name = str
        return this
    end
    function run(data)
        return impl_func(data, column)
    end
end

function make_operator(name, col, func)
    var op = new operator
    op.name = name
    op.column = col
    op.impl_func = func
    return move(op)
end

function avg(col)
    return make_operator("avg", col, impl.avg)
end

function average(col)
    return make_operator("avg", col, impl.avg)
end

function sum(col)
    return make_operator("sum", col, impl.sum)
end

function summery(col)
    return make_operator("sum", col, impl.sum)
end

function count(col)
    return make_operator("count", col, impl.count)
end

function count_distinct(col)
    return make_operator("count_distinct", col, impl.count_distinct)
end

class selection
    var cols = new array
    var raw_data = null
    var header = null
    function filter(cond)
        return __impl_make_dataframe(header, impl.filter(*raw_data, cols, cond))
    end
    function __groupby_impl(iteration, data, idx)
        var result = idx == 0 ? impl.groupby(data, cols.at(idx)) : impl.groupby_group(*raw_data, data, cols.at(idx))
        if iteration > 0
            foreach it in result do it.second = __groupby_impl(iteration - 1, it.second, idx + 1)
        end
        return move(result)
    end
    function groupby()
        return __impl_make_dataframe_groupby(header, raw_data, cols, __groupby_impl(cols.size - 1, *raw_data, 0))
    end
    function aggregate(...args)
        
    end
end

class dataframe
    var header_map = null
    var header = null
    var data = null
    function columns(...args)
        var sel = new selection
        sel.raw_data = &data
        sel.header = header
        if args.empty()
            foreach it in range(header.size) do sel.cols.push_back(it)
        else
            foreach it in args do sel.cols.push_back(header_map.at(it))
        end
        return move(sel)
    end
    function select(...args)
        var cols = new array
        foreach it in args do cols.push_back(header_map.at(it))
        return __impl_make_dataframe(args, impl.select(data, cols))
    end
    function find_broken_lines()
        var lines = new array
        foreach i in range(data.size)
            if data.at(i).size != header.size
                lines.push_back(i + 2)
            end
        end
        return move(lines)
    end
    function to_csv(file)
        var csv_data = data
        csv_data.push_front(header)
        impl.write_csv(csv_data, file)
    end
end

function __get_group_impl(group, key, target)
    if typeid group != typeid hash_map
        throw runtime.exception("Group not exist!")
    end
    if group.exist(key)
        target.push_back(group.at(key))
    else
        foreach it in group do __get_group_impl(it.second, key, target)
    end
end

function __impl_unstack_group_impl(group, target)
    if typeid group == typeid hash_map
        foreach it in group do __impl_unstack_group_impl(it.second, target)
    else
        foreach it in group do target.push_back(it)
    end 
end

function __impl_unstack_group(group, data)
    var lines = new array
    __impl_unstack_group_impl(group, lines)
    var result = new array
    foreach idx in lines do result.push_back(data.at(idx))
    return move(result)
end

function __impl_aggregate_group(data, group, target, operator)
    if typeid group == typeid hash_map
        target = new hash_map
        foreach it in group
            var child_data = null
            __impl_aggregate_group(data, it.second, child_data, operator)
            target.insert(it.first, child_data)
        end
    else
        target = operator.run(data)
    end
end

class dataframe_groupby
    var header_map = null
    var header = null
    var groups = null
    var g_cols = null
    var data = null
    function get_group(key)
        var group_set = new array, lines = new array, result = new array
        __get_group_impl(groups, key, group_set)
        foreach it in group_set do __impl_unstack_group_impl(it, lines)
        foreach idx in lines do result.push_back(data->at(idx))
        return __impl_make_dataframe(header, result)
    end
    function unstack()
        return __impl_make_dataframe(header, __impl_unstack_group(groups, *data))
    end
    function aggregate(...args)
        var result_header = new array, result_map = null
        foreach idx in g_cols do result_header.push_back(header_map.at(idx))
        foreach op in args
            result_header.push_back(op.name)
            __impl_aggregate_group(*data, groups, result_map, op)
        end
    end
end

function read_csv(path)
    var data = impl.read_csv(path)
    if data != null
        link header = data.front
        data.pop_front()
        return __impl_make_dataframe(header, move(data))
    end
end